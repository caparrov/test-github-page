<style>
body {
text-align: justify}
</style>


# Limitations 

### DAG-based performance model

Limitations of our approach to analyzing LLVM IR traces in ERM.

* **Instructions not analyzed in LLVM IR**. From the LLVM IR trace shown in Fig. 2.12(e),
which corresponds to a simple sum reduction, only the highlighted fadd instruction is analyzed
by ERM (all data is in registers and thus there are no loads/stores). The trace, however, contains
many other instructions. The code highlighted in blue in Figs. 2.12(c)â€“2.12(e), for example, corresponds
to the initialization of vector variables from scalar values. The x86 ISA uses a combination
of movss and vinsertps instructions, and the ARM ISA performs vector extractions, vext.32,
on 64-bit registers (128-bit registers in the ARM NEON architecture are mapped onto pairs of 64-
bit registers). LLVM IR, in contrast, does it with the generic instruction insertelement, which
hides the low level-details of this operation on different architectures. In general, the implementation
of these instructions (address calculations, loop indices computations, etc.) varies widely
across architectures, and even across flavors of the same architecture. While they may certainly

* **Effect of compiler optimizations**. Most of the optimizations that have a larger impact on
performance and thus are relevant for our analysis are target-independent, e.g., loop unrolling,
loop vectorization, value propagation, dead code/store elimination, or memory dependence analysis.
Target-specific optimizations (they occur at the code generation phase) are not considered in
the analyzed code. These optimizations are related to instruction selection, SSA-based machine
code optimizations (modulo-scheduling), register allocation (spill code generation and scheduling),
prolog/epilog code insertion (frame-pointer elimination and stack packing), and code emission.
Tables A.1 and A.2 in Appendix A list all the target-independent and target-dependent optimizations,
respectively, included in the -O3 flag in clang.




* **Applications supported by ERM**. ERM can analyze any application dominated by floating
points3 that can be compiled into LLVM IR and either runs through the LLVM interpreter (in case
we follows this approach), or for which we can generate the dynamic task graph, in the case of the
second approach. If the target application uses functions from external libraries, these must be also
compiled into LLVM IR; otherwise, the code of these functions is not considered in the analysis.
In general, straightline C/C++ code can be executed with no effort. Overall, we have been able
to analyze the 24 kernels from the Livermore Loops [9], 10 hand-written kernels including the fast
Fourier Transform or Walsh-Hadamard transform (WHT) from [84], all the kernels automatically
generated by the linear algebra code generator [13] when synthesizing four different linear algebra
functions (a total of 94 kernels variants that implement vector intrinsics), and the KinectFusion
implementation (an application for 3D scene reconstruction) from SLAMBench [8].


